<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>EduardKieser.GitHub.io - Monitor</title>
        <link rel="stylesheet" href="https://eduardkieser.github.io/theme/css/main.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://eduardkieser.github.io/">EduardKieser.GitHub.io</a></h1>
                <nav><ul>
                    <li><a href="https://eduardkieser.github.io/pages/about.html">About</a></li>
                    <li><a href="https://eduardkieser.github.io//">Home</a></li>
                    <li><a href="https://eduardkieser.github.io/category/future-projects.html">Future Projects</a></li>
                    <li><a href="https://eduardkieser.github.io/category/past-projects.html">Past Projects</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="https://eduardkieser.github.io/ICU-Monitor-OCR-Recorder.html">ICU Monitor OCR Recorder: Bridging The Gap in ICU Monitoring</a></h1>
<footer class="post-info">
        <abbr class="published" title="2023-06-19T00:00:00+02:00">
                Published: Mon 19 June 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://eduardkieser.github.io/author/chatgpt-eduard.html">ChatGPT, Eduard</a>
        </address>
<p>In <a href="https://eduardkieser.github.io/category/past-projects.html">Past Projects</a>.</p>
<p>tags: <a href="https://eduardkieser.github.io/tag/healthcare.html">Healthcare</a> <a href="https://eduardkieser.github.io/tag/icu.html">ICU</a> <a href="https://eduardkieser.github.io/tag/ocr.html">OCR</a> <a href="https://eduardkieser.github.io/tag/monitor.html">Monitor</a> <a href="https://eduardkieser.github.io/tag/developing-countries.html">Developing Countries</a> </p>
</footer><!-- /.post-info --><h2>Introduction</h2>
<p>Healthcare in developing countries often lags due to obsolete technology and a lack of resources. One such critical area is Intensive Care Units (ICU), where there's an urgent need to upgrade the system of data logging from monitors. Current systems depend heavily on manual inputs, leading to a significant waste of valuable nursing time and a higher chance of error. This post presents my journey of building a solution to this issue: the ICU Monitor OCR Recorder.</p>
<h2>Identifying the Issue</h2>
<p>Across developing nations, data from ICU monitors often go unrecorded and un-stored. The primary reasons for this include the presence of outdated ICU models from various vendors and each vendor's attempt to establish a closed-off ecosystem. Moreover, the cost of streaming and storing data in such systems can be exorbitantly high. </p>
<p>These factors contribute to a critical yet under-recognized problem. Nurses, already stretched thin in the developing world, spend up to a quarter of their shift manually recording data from each ICU monitor. This is a wasteful use of resources, considering that there's a direct correlation between nurse shortage and higher mortality.  </p>
<p><img alt="How it is" src="images/icu_mon_CurrentStateInSa.png">  </p>
<h2>Developing the Solution</h2>
<p><img alt="How it could be" src="images/icu_mon_FutureStateInSA.png">  </p>
<p>To counter this issue, I focused on the one universal interface that all the devices have to have: The screen. I developed an Optical Character Recognition (OCR) tool to read and log the data from ICU (and other) monitors. This tool, (smartphone running a dedicated app), is positioned in front of the monitor to continuously record the screen. The user annotates the tag for each region of interest (Heart Rate, Respiratory Rate, Photoplethysmogram, Temperature, etc.), once the roi's are marked the user can walk away. From then on a frame is captured at 1Hz, each region of interest is cropped and sent to a custom locally running optical number recognition model. Significant improvement was achieved over tesserachtOCR, which was the best open source OCR solution at the time, by limiting the number of possible characters to 0-9 (and None) and by fixing the possible output length to 3, with one head per number. This meant that the model could only recognize numbers from 0 to 999, but it did so robustly with a (relatively) small backbone (Resnet- 50, I think) and a relatively small data set of &lt; 1m images.</p>
<p><img alt="How it could be" src="images/icu_mon_1.jpg">  </p>
<p>To speed up the process of prototyping and testing, I designed the first POC as a smartphone app, which I developed using Flutter which was the hot new thing at the time. I learned to use flutter specifically for this project, however I still really enjoy using it today.</p>
<h2>Data generation</h2>
<p>I was consumed by this project for a long time and there is a lot to talk about, but the bit that might be most interesting from a machine learning perspective (and telling about my personal style) is the data generation. I needed a fairly large set of annotated pictures of numbers. Ideally these pictures should contain all the artifacts that one should expect from the real world data. To do this I wrote two bits of software, one that generated a series of frames and shoved them into a video file, and one that decoded the same frames from the re-recorded video.
<img alt="Getting data from a real CRT monitor" src="images/icu_mon_4.png">
Each set of number frames was preceded by a marker frame. A marker frame had a bunch of QR codes indicating the location and value of the subsequent numbers. This marker frame was followed by a set of frames that placed the expected numbers at the expected locations.
<img alt="Garage data gen" src="images/icu_mon_1.gif"></p>
<h2>Testing the Solution</h2>
<p>The POC was tested in a clinical setting, garnering positive feedback from both doctors and nurses.
<img alt="The prototype out in the wild" src="images/icu_mon_2.jpeg"> </p>
<p><img alt="Spotted agin!" src="images/icu_mon_3.jpeg"></p>
<h2>Challenges and Future Work</h2>
<p>In the pursuit of funding to elevate the project from POC to a full-scale company, I teamed up with the tech transfer office at my university. As the first step, they filed a patent on my behalf. However, this move ended up being a stumbling block for the project's development.</p>
<p>Fortunately, the patent was only filed in South Africa (South African Patent 2018/04931), so others outside the country are welcome to explore this technology. An excellent professor in the US is currently also pursuing this concept, and I can provide contact details on request.</p>
<h3>Legislation</h3>
<p>Medical certification is often cited as the thing that makes this project infeasible, however I disagree. I don't think that this system should be seen as a medical device. There is no transducer that probes something squishy and wet to come up with a number. It's far more similar to the document scanners that are already in wide spread use in hospitals and are not considered medical devices. Additionally consequences associated with miss classifications are similar to that of a document scanner, however because each classification is re-computed every second (and every sample comes with an associated certainty) it makes error rejection (and continuous improvement) much simpler.  </p>
<h3>The business models</h3>
<p>I hold out hope for two approaches. In one approach it is sold directly to doctors (in it's app form) that will allow them to have a continuous data stream of all their patients, without needing to rely on the broken telephone which currently exists. In the other approach it is sold to the hospital as a system (central node with dedicated camera modules, think esp32CAM), and the hospital can then use it to improve the efficiency of their nurses. The first approach seems easier, but the second approach is more likely to have a large impact. A promising spin on the second approach is to partner with a EMR (Electronic Medical Record) or HIS (Health Information System) providers and sell the solution as an add-on to their existing system. The EMR/HIS market is a fiercely competitive one and no one seems to have a distinguishing feature like this, the first one to implement this will force the rest of the pack to follow suit. In the limit this hack might even be enough to force the big players to open up their systems, which would be a huge win for the healthcare sector in developing countries.</p>
<h2>Conclusion</h2>
<p>My ICU Monitor OCR Recorder was an attempt to bridge a gap in the healthcare sector of developing nations. It's a testament to how a simple hack combined with some machine learning fairy dust can enable improbable systems. 
While I have put down this torch for the time being, I think it's a really powerful idea, and if someone can make it work it will be a real kick in the pants to the powers that be.
I encourage those interested in furthering this project to reach out and continue the journey.</p>                </article>
            </aside><!-- /#featured -->
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>